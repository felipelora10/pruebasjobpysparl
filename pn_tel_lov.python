from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.utils import getResolvedOptions
from pyspark.sql import functions as F
from pyspark.sql.functions import broadcast
from pyspark.sql.window import Window
import uuid
from datetime import datetime
import boto3
import sys


def job_qualtrics_test():
    # ─────────────────────────────────────────────
    # CREAR CONTEXTOS SPARK Y GLUE
    # ─────────────────────────────────────────────
    sc          = SparkContext.getOrCreate()
    glueContext = GlueContext(sc)
    spark       = glueContext.spark_session
    # ─────────────────────────────────────────────
    # CONFIGURACIONES DE OPTIMIZACIÓN DE SPARK (obligatorias)
    # ─────────────────────────────────────────────
    try:
        spark.conf.set("spark.sql.adaptive.enabled",                          "true")
        spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled",       "true")
        spark.conf.set("spark.sql.adaptive.skewJoin.enabled",                 "true")
        spark.conf.set("spark.sql.adaptive.localShuffleReader.enabled",       "true")
        spark.conf.set("spark.sql.adaptive.advisoryPartitionSizeInBytes",     "134217728")
        spark.conf.set("spark.sql.shuffle.partitions",                        "120")
        spark.conf.set("spark.sql.files.maxPartitionBytes",                   "134217728")
        spark.conf.set("spark.sql.autoBroadcastJoinThreshold",                "104857600")
        spark.conf.set("spark.sql.sources.parallelPartitionDiscovery.threshold",  "32")
        spark.conf.set("spark.sql.sources.parallelPartitionDiscovery.parallelism","32")
        spark.conf.set("spark.sql.execution.arrow.maxRecordsPerBatch",        "10000")
        spark.conf.set("spark.sql.execution.arrow.pyspark.enabled",           "true")
        spark.conf.set("spark.sql.adaptive.maxNumPostShufflePartitions",      "120")
        print(" Configuraciones de Spark optimizadas aplicadas")
    except (AttributeError, TypeError, ValueError, RuntimeError) as e:
        print(f" Advertencia: No se pudieron aplicar algunas configuraciones: {str(e)}")
        
    # ─────────────────────────────────────────────
    # CONFIGURACIÓN
    # ─────────────────────────────────────────────
    
    args = getResolvedOptions(sys.argv, ["environment"])
    var_env         = args["environment"]
    connection_name = f"cdata-bocc-{var_env}-glue-db-catalog-redshift"
    temp_dir        = f"s3://cdata-bocc-{var_env}-output/aplicaciones/apl_cdata/salida/qualtrics/"
    
    # -------------------------
    # Helpers de formato
    # -------------------------
    def proper_case(col):
        return F.concat(F.upper(F.substring(col, 1, 1)), F.lower(F.substring(col, 2, 1000)))

    def collapse_spaces(col):
        return F.regexp_replace(F.trim(col), r"\s+", " ")

    def build_fullname(first_col, last_col, maiden_col):
        full = collapse_spaces(F.concat_ws(
            " ",
            F.coalesce(first_col,  F.lit("")),
            F.coalesce(last_col,   F.lit("")),
            F.coalesce(maiden_col, F.lit(""))
        ))
    return proper_case(full)

    def clean_city_desc(desc_col):
        cleaned = collapse_spaces(F.regexp_replace(desc_col, r"\.+\s*$", ""))
        return proper_case(cleaned)
    
    # ─────────────────────────────────────────────
    # HELPER: leer desde Redshift
    # ─────────────────────────────────────────────
    def leer_redshift(query: str):
        return glueContext.create_dynamic_frame_from_options(
            connection_type="redshift",
            connection_options={
                "connectionName"         : connection_name,
                "query"                  : query,
                "redshiftTmpDir"         : temp_dir,
                "useConnectionProperties": True,
            },
        ).toDF()    
     
     
    # ───────────────────────────────────────────── 
    # FASE 1 — PN_BASE_LIGHT
    # ─────────────────────────────────────────────

    def get_query_pn_base_light():
        """
        Devuelve el SQL para PN_BASE_LIGHT.
        """
        return """
        SELECT
          c.ROW_ID                                AS ROW_ID_CLIENTE,
          c.X_OCS_ID_NUM                          AS NUMERO_DE_DOCUMENTO,
          c.X_OCS_ID_TYPE                         AS TIPO_DOC_NAME,
          c.FST_NAME                              AS C_FST_NAME,
          c.LAST_NAME                             AS C_LAST_NAME,
          c.MAIDEN_NAME                           AS C_MAIDEN_NAME,
          c.PR_PER_ADDR_ID,
          c.PR_PHONE_ID,
          c.PR_POSTN_ID,
          pcon.POSTN_ID,
          postn.OU_ID                             AS ORG_ID,
          org.LOC                                 AS COD_DIVISION_GERENTE,
          org.NAME                                AS ORG_NAME,
          postn.NAME                              AS POSTN_NAME,
          emp.ROW_ID                              AS GERENTE_ROW_ID,
          emp.EMP_NUM                             AS CODIGO_SAP_GERENTE,
          emp.FST_NAME                            AS G_FST_NAME,
          emp.LAST_NAME                           AS G_LAST_NAME,
          emp.MAIDEN_NAME                         AS G_MAIDEN_NAME,
          conx.ATTRIB_39                          AS TIPO_ATENCION_NAME,
          per.ADDR                                AS DIRECCION,
          per.CITY                                AS CITY_VAL,
          fnxm.ATTRIB_49                          AS SEGMENTO_NAME,
          fnxm.ATTRIB_50                          AS SEGMENTO_FLAG,
          catalog.DETAIL_TYPE_CD                  AS CLASE_PRODUCTO_VAL
        FROM ADMSIEBEL.S_POSTN_CON pcon
        JOIN ADMSIEBEL.S_POSTN postn          ON pcon.POSTN_ID = postn.ROW_ID
        JOIN ADMSIEBEL.S_CONTACT c            ON pcon.CON_ID = c.ROW_ID
        JOIN ADMSIEBEL.S_ORG_EXT org          ON postn.OU_ID = org.ROW_ID
        JOIN ADMSIEBEL.S_CONTACT emp          ON postn.PR_EMP_ID = emp.ROW_ID
        JOIN ADMSIEBEL.S_EMPLOYEE_X t7        ON t7.PAR_ROW_ID = emp.ROW_ID
        LEFT JOIN ADMSIEBEL.S_CONTACT_X conx  ON conx.PAR_ROW_ID = c.ROW_ID
        LEFT JOIN ADMSIEBEL.S_ADDR_PER per    ON per.ROW_ID = c.PR_PER_ADDR_ID
        JOIN ADMSIEBEL.S_ASSET_CON rel        ON rel.CONTACT_ID = c.ROW_ID
        JOIN ADMSIEBEL.S_ASSET prod           ON rel.ASSET_ID = prod.ROW_ID
        JOIN ADMSIEBEL.S_PROD_INT catalog     ON prod.PROD_ID = catalog.ROW_ID
        JOIN ADMSIEBEL.S_CONTACT_FNXM fnxm    ON c.ROW_ID = fnxm.PAR_ROW_ID
        WHERE c.PR_POSTN_ID = pcon.POSTN_ID
          AND fnxm.ATTRIB_50 = '1000001'
          AND org.NAME <> 'DIRECCION  ONBOARDING Y ASIGNACION'
          AND postn.NAME <> 'Siebel Administrator'
          AND prod.STATUS_CD IN ('1010000')
          AND rel.RELATION_TYPE_CD IN ('Deudor','Titular principal producto')
        """.strip()
    
    # Ejecutar la lectura
    query_PN_BASE_LIGHT = get_query_pn_base_light()
    PN_base = leer_redshift(query_PN_BASE_LIGHT)
    print("Hasta Fase 1 OK")

    # ─────────────────────────────────────────────
    # FASE 2 — LOVs
    # ─────────────────────────────────────────────

    q_lov_multi = """
    SELECT TYPE AS TYPE_NAME, NAME, VAL, HIGH, DESC_TEXT
    FROM ADMSIEBEL.S_LST_OF_VAL
    WHERE TYPE IN (
      'OCS_NID_TYPES',
      'OCS_SEGMENT',
      'OCS_CITY',
      'FINCORP_PROD_ADMIN_CLASS_MLOV',
      'OCS_ATTENTION_TYPE'
    )
    AND ACTIVE_FLG = 'Y'
    """.strip()

    lov_all = (
    leer_redshift(q_lov_multi)
    .withColumnRenamed("NAME", "LOV_NAME")
    .withColumnRenamed("VAL", "LOV_VAL")
    .withColumnRenamed("HIGH", "LOV_HIGH")
    .withColumnRenamed("DESC_TEXT", "LOV_DESC")
    )
    
    # Particionarlo en 5 DataFrames según el TYPE (en Spark)
    lov_nid     = lov_all.filter(F.col("TYPE_NAME") == "OCS_NID_TYPES"                 ).select("LOV_NAME","LOV_HIGH")
    lov_segment = lov_all.filter(F.col("TYPE_NAME") == "OCS_SEGMENT"                   ).select("LOV_NAME","LOV_DESC")
    lov_city    = lov_all.filter(F.col("TYPE_NAME") == "OCS_CITY"                      ).select("LOV_VAL","LOV_DESC")
    lov_prod    = lov_all.filter(F.col("TYPE_NAME") == "FINCORP_PROD_ADMIN_CLASS_MLOV" ).select("LOV_VAL","LOV_DESC")
    lov_att     = lov_all.filter(F.col("TYPE_NAME") == "OCS_ATTENTION_TYPE"            ).select("LOV_NAME","LOV_DESC")
    print("lov_all:", lov_all.count())
    print("Hasta Fase 2 OK")
    
    # ─────────────────────────────────────────────
    # FASE 3 — HELPERS FORMATO + ENRIQUECIMIENTO
    # ─────────────────────────────────────────────
    print("\n[FASE 3] Helpers + PN_enriched...")
    
    # Helpers simples (igual SQL cliente)


    PN_enriched = (  
    PN_base
        # Tipo de documento: join por NAME → exponer HIGH
        .join(
            broadcast(lov_nid).alias("lv_nid"),
            F.col("TIPO_DOC_NAME") == F.col("lv_nid.LOV_NAME"),
            "left"
        )
        .withColumn("TIPO_DE_DOCUMENTO_COD", F.col("lv_nid.LOV_HIGH"))

        # Segmento: join por NAME → exponer DESC
        .join(
            broadcast(lov_segment).alias("lv_seg"),
            F.col("SEGMENTO_NAME") == F.col("lv_seg.LOV_NAME"),
            "left"
        )
        .withColumn("SEGMENTO_COMERCIAL_CLIENTE", F.col("lv_seg.LOV_DESC"))

        # Tipo de atención: join por NAME → exponer DESC
        .join(
            broadcast(lov_att).alias("lv_att"),
            F.col("TIPO_ATENCION_NAME") == F.col("lv_att.LOV_NAME"),
            "left"
        )
        .withColumn("TIPO_ATENCION_DESC", F.col("lv_att.LOV_DESC"))

        # Ciudad: join por VAL → exponer DESC (limpiando formato)
        .join(
            broadcast(lov_city).alias("lv_city"),
            F.col("CITY_VAL") == F.col("lv_city.LOV_VAL"),
            "left"
        )
        .withColumn("CIUDAD_DESC", clean_city_desc(F.col("lv_city.LOV_DESC")))

        # Clase producto: join por VAL → exponer DESC
        .join(
            broadcast(lov_prod).alias("lv_prod"),
            F.col("CLASE_PRODUCTO_VAL") == F.col("lv_prod.LOV_VAL"), 
            "left"
        )
        .withColumn("CLASE_PRODUCTO_DESC", F.col("lv_prod.LOV_DESC"))


        # Nombres formateados (cliente y gerente)
        .withColumn(
            "NOMBRE_CLIENTE",
            build_fullname(F.col("C_FST_NAME"), F.col("C_LAST_NAME"), F.col("C_MAIDEN_NAME"))  
        )
        .withColumn(
            "NOMBRE_GERENTE",
            build_fullname(F.col("G_FST_NAME"), F.col("G_LAST_NAME"), F.col("G_MAIDEN_NAME"))

        )
        # Filtro de segmentos válidos (igual que tu SQL)
        .filter(F.col("SEGMENTO_COMERCIAL_CLIENTE").isin(
            'BP - Selecto','BP - Preferente Plus','BP - Elite Plus',
            'BP - Masivo','BP - Mi Grupo es Aval','BP - Preferente','BP - Elite'
        ))

        # Selección para continuar con teléfonos y clases
        .select(
            "ROW_ID_CLIENTE","NUMERO_DE_DOCUMENTO",
            "TIPO_DE_DOCUMENTO_COD",
            "NOMBRE_CLIENTE",
            "COD_DIVISION_GERENTE",
            "NOMBRE_GERENTE",
            "CODIGO_SAP_GERENTE",
            F.col("SEGMENTO_COMERCIAL_CLIENTE").alias("SEGMENTO"),
            F.col("TIPO_ATENCION_DESC").alias("TIPO_ATENCION"),
            "DIRECCION",
            F.col("CIUDAD_DESC").alias("CIUDAD"),
            F.col("CLASE_PRODUCTO_DESC").alias("CLASE_PRODUCTO"),
            "PR_PHONE_ID"
        )
    )
    print("Hasta Fase 3 OK")

    # ─────────────────────────────────────────────
    # FASE 4 — PHONES LIGHT
    # ─────────────────────────────────────────────
    
    query_PHONES_LIGHT = """
        SELECT
          p.CON_ID         AS ORG_ID,
          p.ROW_ID         AS PHONE_ROW_ID,
          p.X_OCS_PHONE_NUM,
          p.X_OCS_EXTENSION,
          p.X_OCS_END_DATE
        FROM ADMSIEBEL.S_CON_PHONE p
        WHERE p.X_OCS_END_DATE IS NULL
    """.strip()
    
    phones_raw = leer_redshift(query_PHONES_LIGHT)      
    print("phones_raw:", phones_raw.count())
    print("Hasta Fase 4 OK")
    
    job_qualtrics_test()
